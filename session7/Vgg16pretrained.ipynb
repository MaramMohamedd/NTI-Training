{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832d1b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten , Conv2D , Dense , Dropout\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG16 \n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d0f9aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train , y_train) , (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb62b83f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'size' must be a 1-D Tensor of 2 elements: new_height, new_width",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m x_train = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m x_test = tf.image.resize(x_test , (\u001b[32m224\u001b[39m,\u001b[32m224\u001b[39m , \u001b[32m3\u001b[39m))\n\u001b[32m      4\u001b[39m x_train = x_train / \u001b[32m255.0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:1477\u001b[39m, in \u001b[36m_resize_images_common\u001b[39m\u001b[34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[39m\n\u001b[32m   1475\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33msize\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33m must be a 1-D int32 Tensor\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m size.get_shape().is_compatible_with([\u001b[32m2\u001b[39m]):\n\u001b[32m-> \u001b[39m\u001b[32m1477\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33msize\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33m must be a 1-D Tensor of 2 elements: \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1478\u001b[39m                    \u001b[33m'\u001b[39m\u001b[33mnew_height, new_width\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m preserve_aspect_ratio:\n\u001b[32m   1481\u001b[39m   \u001b[38;5;66;03m# Get the current shapes of the image, even if dynamic.\u001b[39;00m\n\u001b[32m   1482\u001b[39m   _, current_height, current_width, _ = _ImageDimensions(images, rank=\u001b[32m4\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: 'size' must be a 1-D Tensor of 2 elements: new_height, new_width"
     ]
    }
   ],
   "source": [
    "x_train = tf.image.resize(x_train , (224,224 ,3))\n",
    "x_test = tf.image.resize(x_test , (224,224 , 3))\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "y_train = to_categorical(y_train , 10)\n",
    "y_test = to_categorical(y_test , 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709c48ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet' , include_top=False , input_shape=(224, 224,3))\n",
    "base_model.trainable = False \n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(1000 , activation='relu')(x)\n",
    "Dropout(0.5)(x)\n",
    "prediction =Dense(10, activation='softmax')(x)\n",
    "\n",
    "\n",
    "#Model = bas_model (all layers untill the fc layers )+ manuall fc layers \n",
    "#compiling , fitting , evaluating \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
